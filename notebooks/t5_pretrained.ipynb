{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1986ca64",
   "metadata": {},
   "source": [
    "# Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4f091",
   "metadata": {},
   "source": [
    "# Relative Paths for models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf1002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = \"../models/\"\n",
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d3096",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64de63d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdb11f8af8b41b685806d719a257f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path + \"filtered_reviews.csv\", usecols=[\"Id\",\"Summary\", \"Text\", \"ProductId\"])\n",
    "df.dropna(subset=[\"Summary\", \"Text\"], inplace=True)\n",
    "\n",
    "df = df.sample(10000, random_state=42) # Testing fintetuning with a small dataset currently\n",
    "\n",
    "df = df.rename(columns={\"Summary\": \"target_text\", \"Text\": \"input_text\"})\n",
    "\n",
    "dataset = Dataset.from_pandas(df) # converting to HF Dataset format since we will be using T5 transformer model from HF\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Step 4: Preprocessing function (from this paper for encoding summarization task page 47: https://arxiv.org/pdf/1910.10683)\n",
    "def preprocess_function(example):\n",
    "    input_text = \"summarize: \" + example[\"input_text\"]\n",
    "    model_inputs = tokenizer(\n",
    "        input_text, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        example[\"target_text\"], max_length=64, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=False)\n",
    "\n",
    "# Train/test Split\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = split[\"train\"]\n",
    "eval_dataset = split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74abeaf7",
   "metadata": {},
   "source": [
    "# Finetuning T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5846e88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21bdedd74044ebd9e197048cc4a169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.7543, 'grad_norm': 1.6389862298965454, 'learning_rate': 4.8592592592592596e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5825, 'grad_norm': 1.141833782196045, 'learning_rate': 4.711111111111111e-05, 'epoch': 0.18}\n",
      "{'loss': 0.476, 'grad_norm': 0.7669867873191833, 'learning_rate': 4.5629629629629636e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4486, 'grad_norm': 0.7971938252449036, 'learning_rate': 4.414814814814815e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4361, 'grad_norm': 0.5160514116287231, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.44}\n",
      "{'loss': 0.4571, 'grad_norm': 0.5493866205215454, 'learning_rate': 4.1185185185185186e-05, 'epoch': 0.53}\n",
      "{'loss': 0.4261, 'grad_norm': 0.5630396008491516, 'learning_rate': 3.97037037037037e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4342, 'grad_norm': 0.4969012141227722, 'learning_rate': 3.8222222222222226e-05, 'epoch': 0.71}\n",
      "{'loss': 0.4169, 'grad_norm': 0.5673686861991882, 'learning_rate': 3.674074074074074e-05, 'epoch': 0.8}\n",
      "{'loss': 0.4256, 'grad_norm': 0.7762271165847778, 'learning_rate': 3.525925925925926e-05, 'epoch': 0.89}\n",
      "{'loss': 0.422, 'grad_norm': 0.7512151598930359, 'learning_rate': 3.377777777777778e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580517bf99fe446ebdcafc9b1293ba33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39003264904022217, 'eval_runtime': 10.8735, 'eval_samples_per_second': 91.967, 'eval_steps_per_second': 11.496, 'epoch': 1.0}\n",
      "{'loss': 0.4242, 'grad_norm': 0.5085411071777344, 'learning_rate': 3.22962962962963e-05, 'epoch': 1.07}\n",
      "{'loss': 0.4209, 'grad_norm': 0.6219936609268188, 'learning_rate': 3.0814814814814816e-05, 'epoch': 1.16}\n",
      "{'loss': 0.4126, 'grad_norm': 0.6410334706306458, 'learning_rate': 2.9333333333333336e-05, 'epoch': 1.24}\n",
      "{'loss': 0.4113, 'grad_norm': 0.5282003283500671, 'learning_rate': 2.7851851851851853e-05, 'epoch': 1.33}\n",
      "{'loss': 0.4157, 'grad_norm': 0.5552299618721008, 'learning_rate': 2.6370370370370373e-05, 'epoch': 1.42}\n",
      "{'loss': 0.4068, 'grad_norm': 0.8922046422958374, 'learning_rate': 2.488888888888889e-05, 'epoch': 1.51}\n",
      "{'loss': 0.4087, 'grad_norm': 0.522246778011322, 'learning_rate': 2.340740740740741e-05, 'epoch': 1.6}\n",
      "{'loss': 0.4004, 'grad_norm': 0.746623694896698, 'learning_rate': 2.1925925925925926e-05, 'epoch': 1.69}\n",
      "{'loss': 0.4186, 'grad_norm': 0.8416483998298645, 'learning_rate': 2.0444444444444446e-05, 'epoch': 1.78}\n",
      "{'loss': 0.4095, 'grad_norm': 0.5960798263549805, 'learning_rate': 1.8962962962962963e-05, 'epoch': 1.87}\n",
      "{'loss': 0.4038, 'grad_norm': 0.41943204402923584, 'learning_rate': 1.7481481481481483e-05, 'epoch': 1.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06fa2eee95040fdbd9aa7e278f8ff16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3831178545951843, 'eval_runtime': 11.2894, 'eval_samples_per_second': 88.579, 'eval_steps_per_second': 11.072, 'epoch': 2.0}\n",
      "{'loss': 0.3925, 'grad_norm': 0.5014961361885071, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.04}\n",
      "{'loss': 0.4093, 'grad_norm': 0.4830264449119568, 'learning_rate': 1.4518518518518521e-05, 'epoch': 2.13}\n",
      "{'loss': 0.4062, 'grad_norm': 0.8073115944862366, 'learning_rate': 1.3037037037037036e-05, 'epoch': 2.22}\n",
      "{'loss': 0.4107, 'grad_norm': 0.5469932556152344, 'learning_rate': 1.1555555555555556e-05, 'epoch': 2.31}\n",
      "{'loss': 0.3978, 'grad_norm': 0.5385692715644836, 'learning_rate': 1.0074074074074074e-05, 'epoch': 2.4}\n",
      "{'loss': 0.3982, 'grad_norm': 0.736526608467102, 'learning_rate': 8.592592592592593e-06, 'epoch': 2.49}\n",
      "{'loss': 0.397, 'grad_norm': 0.6076058149337769, 'learning_rate': 7.111111111111112e-06, 'epoch': 2.58}\n",
      "{'loss': 0.4044, 'grad_norm': 0.4985710680484772, 'learning_rate': 5.62962962962963e-06, 'epoch': 2.67}\n",
      "{'loss': 0.4104, 'grad_norm': 0.5947009325027466, 'learning_rate': 4.1481481481481485e-06, 'epoch': 2.76}\n",
      "{'loss': 0.4078, 'grad_norm': 0.6881885528564453, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.84}\n",
      "{'loss': 0.4002, 'grad_norm': 0.4913395643234253, 'learning_rate': 1.1851851851851852e-06, 'epoch': 2.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d67a167c6ae47859eb5ccc9dc5b1cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3816366195678711, 'eval_runtime': 11.2954, 'eval_samples_per_second': 88.532, 'eval_steps_per_second': 11.066, 'epoch': 3.0}\n",
      "{'train_runtime': 864.1731, 'train_samples_per_second': 31.244, 'train_steps_per_second': 3.905, 'train_loss': 0.5195833700674551, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/t5_summarizer\\\\tokenizer_config.json',\n",
       " '../models/t5_summarizer\\\\special_tokens_map.json',\n",
       " '../models/t5_summarizer\\\\spiece.model',\n",
       " '../models/t5_summarizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= models_path + \"t5_summarizer\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir= models_path + \"logs\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(models_path + \"t5_summarizer\")\n",
    "tokenizer.save_pretrained(models_path + \"t5_summarizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f61df8",
   "metadata": {},
   "source": [
    "# Testing finetune T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c7a87",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c442b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4062c56895f466a9fae961d70c7066f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3365426848e4a31a60a1ff0ca5ee775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a791f6fc9df446b83955025da05f074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716fe81bc327489e8c67f43ae8e2c630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mohamed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mohamed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Mohamed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")  \n",
    "meteor = evaluate.load(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8316f17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initial model Loading\n",
    "initial_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "initial_model.to(device)\n",
    "\n",
    "# Finetuned model Loading\n",
    "finetuned_model_path = \"../models/t5_summarizer\"\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(finetuned_model_path)\n",
    "finetuned_tokenizer = T5Tokenizer.from_pretrained(finetuned_model_path)\n",
    "finetuned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a65782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Metrics:\n",
      "ROUGE-L (Initial pre-trained model): 0.0890\n",
      "BLEU (Initial pre-trained model): 0.0036\n",
      "METEOR (Initial pre-trained model): 0.1272\n",
      "\n",
      "Fine-tuned Model Metrics:\n",
      "ROUGE-L (Fine-tuned model): 0.1432\n",
      "BLEU (Fine-tuned model): 0.0000\n",
      "METEOR (Fine-tuned model): 0.0865\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model_to_eval, dataset, tokenizer, max_input_length=512, max_target_length=64):\n",
    "    model_to_eval.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in dataset.select(range(200)):\n",
    "        input_text = \"summarize: \" + example[\"input_text\"]\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "        input_ids = input_ids.to(model_to_eval.device)\n",
    "        with torch.no_grad():\n",
    "            output_ids = model_to_eval.generate(input_ids, max_length=max_target_length)\n",
    "        pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        predictions.append(pred)\n",
    "        references.append(example[\"target_text\"])\n",
    "    \n",
    "    results = {}\n",
    "    # ROUGE-L\n",
    "    rouge_results = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "    results[\"rougeL\"] = rouge_results[\"rougeL\"]\n",
    "    # BLEU score\n",
    "    bleu_results = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n",
    "    results[\"bleu\"] = bleu_results[\"bleu\"]\n",
    "    # METEOR score\n",
    "    meteor_results = meteor.compute(predictions=predictions, references=references)\n",
    "    results[\"meteor\"] = meteor_results[\"meteor\"]\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initial model\n",
    "initial_results = evaluate_model(initial_model, eval_dataset, tokenizer)\n",
    "print(\"Initial Model Metrics:\")\n",
    "print(f\"ROUGE-L (Initial pre-trained model): {initial_results['rougeL']:.4f}\")\n",
    "print(f\"BLEU (Initial pre-trained model): {initial_results['bleu']:.4f}\")\n",
    "print(f\"METEOR (Initial pre-trained model): {initial_results['meteor']:.4f}\")\n",
    "\n",
    "# Fine-tuned model\n",
    "finetuned_results = evaluate_model(finetuned_model, eval_dataset, tokenizer)\n",
    "print(\"\\nFine-tuned Model Metrics:\")\n",
    "print(f\"ROUGE-L (Fine-tuned model): {finetuned_results['rougeL']:.4f}\")\n",
    "print(f\"BLEU (Fine-tuned model): {finetuned_results['bleu']:.4f}\")\n",
    "print(f\"METEOR (Fine-tuned model): {finetuned_results['meteor']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ec7ed",
   "metadata": {},
   "source": [
    "A 60% increase in ROUGE accuracy. However, BLEU and METEOR dropped significantly in accuracy. A higher BLEU score for the initial model supports the reasoning of data leakage for the initial model (which is possible since T5 HF model is trained on public available data - our dataset).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
